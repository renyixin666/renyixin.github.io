---
title: "Transformer 可视化"
date: 2025-07-23
layout: single
collection: notes
---

## Key Concepts

- Self-attention mechanism
- Positional encoding
- Multi-head attention
- Layer normalization

📎 [Download Poster (PDF)](/files/paper1.pdf)
